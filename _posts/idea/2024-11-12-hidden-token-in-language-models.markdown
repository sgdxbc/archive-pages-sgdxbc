---
layout: post
title:  （大）语言模型中的隐词元
date:   2024-11-12 19:48:29 +0800
categories: [点子]
---

> (我：大语言模型中的“token”这一概念怎么翻译成中文)
>
> 在大语言模型（如GPT系列）中，"token" 这个词通常翻译为“词元”或“符号”。具体来说：
>
> 词元：这个翻译强调了“token”是自然语言中的一个基本单位，但它不仅仅限于单个词语，也可以是一个词的一部分（如词根、前缀、后缀等），或者是标点符号、空格等。一个“token”可以是文本中的任何一个构成单位。
>
> 符号：在某些上下文中，也有将“token”翻译为“符号”的情况，这主要是在更抽象的层面上使用，例如计算机科学中有时会将它理解为一种符号或符号序列。
>
> 总结来说，“词元”是最常见的翻译，因为它能够更好地涵盖自然语言处理中各种语言单位的多样性。
>
> —— ChatGPT 4o mini

### 背景

在大模型中输入的文本被依次转化为词元，然后输出的词元又被依次转化为文本。文本和词元之间有着（几乎）一一对应关系。起码，每个词元对应的文本。

### 提议

允许大模型使用一些隐词元。不对应任何文本，因此不会在预装填（prefilling）过程中出现，但是可以随时出现在大模型的输出中。当大模型输出一个隐词元时，不输出任何文本，但是将这个隐词元如同普通词元一样反馈至下一个解码过程的输入当中。

### 理由

> rationale也是个不太能翻译的词。
{: .prompt-tip }

大的背景还是「解码下一个词元」变幻莫测的难度与解码过程的固定计算量之间的不匹配。（虽然这个思考系列好像还没在这个站的内容中出现过。）

除了先前就知道的一些可以争取到更多计算量的技巧（如chain of thoughts，初代prompt engineering「step by step」等），最近还学到了early exiting，可以在遇到计算量过剩的解码时降低计算量的技术。嘛，总之就是不能匹配。

隐词元的内在思想是将大模型的「思考」和「输出」解耦开。不用只基于自己说出的话顺着说下去，也不用反过来，把后面需要用到的思考材料全都说出来。某种意义上，就像说一句，然后吐一句内心OS，然后再说一句，以此类推。（似乎有见到过OpenAI的类似做法。）

这听起来有点像我写出来的东西。等等我是什么东西（

### 挑战

怎么训练。展开讨论略。
