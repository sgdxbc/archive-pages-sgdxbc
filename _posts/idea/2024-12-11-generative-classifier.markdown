---
layout: post
title:  生成式（图像）分类
date:   2024-12-11 10:41:05 +0800
categories: [点子]
---

端到端的图像分类可以被拆解成生成和分类两个步骤。

生成阶段根据输入图像进行图生文，分类阶段根据生成的段落进行一轮对话。

**好处。**避免了仅编码器架构的固定计算量限制；图生文环节可以进行任意复杂的推理，虽然有多大用就不一定了。

可以查阅图生文的中间结果，分析是哪个环节成为了精确度瓶颈，针对性地做优化。

两个阶段分别都可以使用通用模型，无需根据分类标签专门训练。

----

似乎稳定扩散模型的规模一般是比语言模型要小的，训练代价更加负担得起。

生成阶段可以使用一个根据分类标签专门训练/精调（fine tuning）的扩散模型做进一步地加强。

扩散模型需要以被分类的图像作为提示符，绘制一组在它看来（在分类标签的意义下）类似于被分类图像的图像簇，然后各自做分类并加权得到最终结果。

直觉：别急着收敛到分类标签，咱们先发散一下觉得对图里这玩意有什么印象没有？

可以将扩散模型视作对训练集的一种模糊索引，将扩散模型本身视作对训练集的生成式取回（generative retrival）。只不过通常生成式取回是对数据集提前做推理得到「静态」索引，而这里更像是搞出了某种「随机应变（ad hoc）」索引。
